{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from __future__ import unicode_literals, print_function, division\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "import math\n",
    "from ML_utils import ML_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_space(list_in):\n",
    "    index = []\n",
    "    for num in range(len(list_in)):        \n",
    "        remove_num = 0\n",
    "        if list_in[num] == \"\" or list_in[num] == \"\\u3000\":\n",
    "            index.append(num)\n",
    "    for num in range(len(index)):\n",
    "        remove_index = index[num]-remove_num\n",
    "        list_in.pop(remove_index)\n",
    "        remove_num = remove_num+1\n",
    "    return list_in\n",
    "\n",
    "def file_to_word_list(data_path,clip_len):\n",
    "    pairs = []\n",
    "    with open(data_path,\"r\",encoding=\"utf-8\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            pair = line.split(\"\\t\")\n",
    "            X = pair[0].strip(\" \").split(\" \")\n",
    "            X = del_space(X)\n",
    "            Y = pair[1].strip(\"\\n\").strip(\" \").split(\" \")\n",
    "            Y = del_space(Y)\n",
    "            if (len(X) <= clip_len) and (len(Y) <= clip_len):\n",
    "                pairs.append([X,Y])            \n",
    "    return pairs\n",
    "\n",
    "def prepareData_vec(word_vectors,pairs,pairs_len):\n",
    "    num = np.random.randint(0,pairs_len,1,np.int32)[0]\n",
    "    pair = pairs[num]\n",
    "    x = []\n",
    "    y = []\n",
    "    for word in pair[0]:\n",
    "        x.append(word_vectors.get_vector(word))\n",
    "    for word in pair[1]:\n",
    "        y.append(word_vectors.get_vector(word))\n",
    "    return x,y\n",
    "\n",
    "def strlist_to_vec(word_vectors,strlist):    \n",
    "    x = []\n",
    "    for word in strlist:\n",
    "        x.append(word_vectors.get_vector(word))\n",
    "    return x\n",
    "\n",
    "def wordvec2str(word_vectors,vec):\n",
    "    return word_vectors.similar_by_vector(vec,1)\n",
    "\n",
    "def showPlot(points):\n",
    "    fig = plt.figure()\n",
    "    subfig = plt.subplot(111)\n",
    "    subfig.plot(points)\n",
    "    plt.show()\n",
    "\n",
    "def showPlot_avg(plot_losses,accumulation_num):\n",
    "    new_list = []\n",
    "    value = 0\n",
    "    for i,v in enumerate(plot_losses):\n",
    "        value = value+plot_losses[i]\n",
    "        if ((i+1)%accumulation_num) == 0:\n",
    "            new_list.append(value)\n",
    "            value = 0 \n",
    "    plt.plot(new_list)\n",
    "    \n",
    "#除以60秒向下取整換算成分鐘\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    #除後剩下的秒數\n",
    "    s -= m * 60\n",
    "    #傳回換算好的幾分幾秒\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    #記錄現在的時間\n",
    "    now = time.time()\n",
    "    #秒數為現在減去之前開始訓練時的時間，兩個的時間差\n",
    "    s = now - since\n",
    "    #秒數除以現在完成百分比，等於推測總共需要的秒數\n",
    "    es = s / (percent)\n",
    "    #rs等於剩下的秒數\n",
    "    rs = es - s\n",
    "    #將用了幾秒以及剩幾秒換算成幾分幾秒傳回\n",
    "    return '{0} (remaining {1})'.format(asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#格式為(GRU_layer_num,batch_size,hidden_size)。\n",
    "def initHidden(rnn_num_layers,hidden_size,device):\n",
    "    return torch.zeros(rnn_num_layers, 1, hidden_size, device=device)\n",
    "#建立用來儲存encoder_output的tensor\n",
    "def init_encoder_outputs(max_len,e_output_size,device):\n",
    "    return torch.zeros(max_len, e_output_size, device=device)\n",
    "\n",
    "#建立模型\n",
    "class EncoderRNN(nn.Module):\n",
    "    #input是字index，格式為(seq_len,batch_size,wordvec_size)\n",
    "    def __init__(self, input_size, hidden_size, output_size, rnn_num_layers,max_length):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, rnn_num_layers)\n",
    "        self.encoder_output = nn.Linear(hidden_size, hidden_size)\n",
    "        self.encoder_output1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.encoder_output2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #output = (seq_len, batch, num_directions(=1) * hidden_size)\n",
    "        output = input.reshape(1,1,self.input_size)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = output.reshape(-1,self.hidden_size)\n",
    "        output = nn.functional.tanh(output)\n",
    "        output = self.encoder_output(output)\n",
    "        output = nn.functional.tanh(output)\n",
    "        output = self.encoder_output1(output)\n",
    "        output = self.encoder_output2(output)\n",
    "        return output, hidden\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, e_output_size, d_output_size,\n",
    "                 rnn_num_layers,max_length, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.e_output_size = e_output_size\n",
    "        self.d_output_size = d_output_size\n",
    "        self.max_length = max_length\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = nn.Linear(int((max_length*e_output_size)+input_size), max_length)\n",
    "        self.gru = nn.GRU(input_size+e_output_size, hidden_size, rnn_num_layers)\n",
    "        self.decoder_output = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder_output1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder_output2 = nn.Linear(hidden_size, d_output_size)\n",
    "               \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        output = input.reshape(1,1,self.input_size)\n",
    "#         output = self.dropout(output)\n",
    "        attn_weights = nn.functional.softmax(self.attn(torch.cat((encoder_outputs.reshape(-1),input), 0)),dim=0)\n",
    "        attn_weights = attn_weights.reshape(1,self.max_length)\n",
    "        attn_applied = torch.mm(attn_weights,encoder_outputs)\n",
    "        attn_applied = attn_applied.reshape(1,1,self.e_output_size)\n",
    "        output = torch.cat((attn_applied, output), 2)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = output.reshape(-1,self.hidden_size)\n",
    "        output = nn.functional.tanh(output)\n",
    "        output = self.decoder_output(output) \n",
    "        output = nn.functional.tanh(output)\n",
    "        output = self.decoder_output1(output)\n",
    "        output = self.decoder_output2(output)\n",
    "        output = output.reshape(-1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練\n",
    "#多少比例使用teacher_forcing\n",
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio=0.5):\n",
    "    #encoder_hidden 初始化encoder的h0\n",
    "    encoder_hidden = initHidden(encoder.rnn_num_layers,encoder.hidden_size,device=device)\n",
    "    #先將encoder_optimizer、decoder_optimizer梯度清零\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #計算input跟output句子長度(seq_len)\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    #encoder_outputs =  torch.zeros(max_length, encoder.hidden_size)，初始化encoder的output\n",
    "    #用來記錄每一個seq輸出的output\n",
    "    encoder_outputs = init_encoder_outputs(encoder.max_length, encoder.output_size, device=device)\n",
    "    #清零loss\n",
    "    loss = 0\n",
    "    #循環input_length次數\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        #輸出的encoder_output格式為(GRU_layer_num,batch_size,hidden_size)\n",
    "        #encoder_outputs = (max_length, encoder.output_size)\n",
    "        #如果input_length < max_length，則其餘沒被修改到的encoder_outputs為zeros\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    #解碼輸入第一個input = SOS_token(index=0)，decoder_input.shape=(1,1)\n",
    "    decoder_input = target_tensor[0]\n",
    "    #decoder_hidden初始化\n",
    "    decoder_hidden = initHidden(encoder.rnn_num_layers,decoder.hidden_size, device=device)\n",
    "    #如果random.random() < teacher_forcing_ratio為True，否則False\n",
    "    #random.random() 0~1隨機數\n",
    "    if random.random() < teacher_forcing_ratio:\n",
    "        use_teacher_forcing = True\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    #如果為真\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing\n",
    "        #最後一個EOS不輸入(因為沒東西可以預測)\n",
    "        for di in range(target_length-1):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)  \n",
    "            #計算loss加總\n",
    "            loss += criterion(decoder_output, target_tensor[di+1])\n",
    "            #將target_tensor答案作為下個序列的輸入\n",
    "            decoder_input = target_tensor[di+1] \n",
    "\n",
    "    else:\n",
    "        for di in range(target_length-1):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #計算loss加總\n",
    "            loss += criterion(decoder_output, target_tensor[di+1])\n",
    "            #將decoder_output作為下個序列的輸入\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "    #計算梯度\n",
    "    loss.backward()\n",
    "    #更新權重\n",
    "    for p in encoder.parameters():\n",
    "        torch.nn.utils.clip_grad_norm_(p, 2)\n",
    "    for p in decoder.parameters():\n",
    "        torch.nn.utils.clip_grad_norm_(p, 2)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #傳回loss除以target_length，這一個句子的平均loss\n",
    "    return loss.item() / (target_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_iters = 迭代次數\n",
    "#print_every 每幾次打印進度\n",
    "#plot_every 每幾次紀錄繪圖\n",
    "#learning_rate 學習率\n",
    "#encoder、decoder 編解碼的類\n",
    "\n",
    "def trainIters(plot_losses,encoder, decoder, dtype, device ,n_iters ,print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    pairs_len = len(pairs)\n",
    "    start = time.time()\n",
    "    #紀錄迭代次數\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    #iter = 1~n_iters\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        #取第一筆training_pairs\n",
    "        x,y = prepareData_vec(word_vectors,pairs,pairs_len)\n",
    "        #個別取出input_tensor、target_tensor，Tensor.shape=(seq_len+1(EOS_token),1) \n",
    "        input_tensor = torch.tensor(x,dtype=dtype,device=device)\n",
    "        target_tensor = torch.tensor(y,dtype=dtype,device=device)\n",
    "        #開始訓練 \n",
    "        #傳回傳入這一個句子訓練時每個字的平均loss\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion,teacher_forcing_ratio=1)\n",
    "        #將loss加總\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        #如果迭代次數到了指定打印次數\n",
    "        if iter % print_every == 0:\n",
    "            #計算迭代了 print_every 句的句子平均loss\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            #總紀錄loss清零重新記錄\n",
    "            print_loss_total = 0\n",
    "            #打印用了多少時間(幾分幾秒)、預計還要跑多少時間、目前迭代幾次、完成百分之多少、目前平均loss\n",
    "            print('%s (%d %.1f%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "        #如果迭代次數到了指定繪圖次數\n",
    "        if iter % plot_every == 0:\n",
    "            #計算迭代了 plot_every 句的句子平均loss\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            #存入要繪圖的列表\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            #總紀錄loss清零重新記錄\n",
    "            plot_loss_total = 0\n",
    "    #繪圖\n",
    "    showPlot(plot_losses)\n",
    "    showPlot_avg(plot_losses,10)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "data_path = r\"D:\\Backup\\ml_data\\GitHub\\chat-robot_seq2seq\\data\\merge_ptt_token_jieba1.txt\"\n",
    "model_path = r\"D:\\Backup\\ml_data\\GitHub\\chat-robot_seq2seq\\word2vec_model\\keyvector\\model_keyvector\"\n",
    "max_seq_len = 22\n",
    "rnn_num_layers = 3\n",
    "e_input_size = 300\n",
    "e_hidden_size = 400\n",
    "e_output_size = 300\n",
    "d_input_size = 300\n",
    "d_hidden_size = 800\n",
    "d_output_size = 300\n",
    "e_h0 = initHidden(rnn_num_layers,e_hidden_size, device=device)\n",
    "d_h0 = initHidden(rnn_num_layers,d_hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = file_to_word_list(data_path,max_seq_len)\n",
    "word_vectors = KeyedVectors.load(model_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(e_input_size, e_hidden_size,e_output_size,rnn_num_layers,max_seq_len).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(d_input_size, d_hidden_size,e_output_size,d_output_size,\n",
    "                               rnn_num_layers,max_seq_len,dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立空列表紀錄要繪圖的losses\n",
    "plot_losses = []\n",
    "plot_losses = trainIters(plot_losses,encoder1, attn_decoder1,dtype,device,\n",
    "                         n_iters=600000, print_every=200,plot_every=200, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showPlot(plot_losses)\n",
    "showPlot_avg(plot_losses,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#儲存\n",
    "save_encoder_path = r'D:\\Backup\\ml_data\\GitHub\\chat-robot_seq2seq\\word2vec_model\\model\\encoder'\n",
    "save_decoder_path = r'D:\\Backup\\ml_data\\GitHub\\chat-robot_seq2seq\\word2vec_model\\model\\decoder'\n",
    "torch.save(encoder1.state_dict(), save_encoder_path)\n",
    "torch.save(attn_decoder1.state_dict(), save_decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#評估\n",
    "#傳入encoder、decoder、你輸入的句子、max_length\n",
    "def evaluate(sentence,encoder, decoder, max_length):\n",
    "    userdict_path = './jieba_dict/ptt_userdict.txt'\n",
    "    jieba_dict = 'jieba_dict/jieba_merge.txt'\n",
    "    sentence = ML_utils.Jieba_str_segmentation(sentence,\n",
    "                                           dict_path=jieba_dict,\n",
    "                                           load_userdict_path=userdict_path,split=True,HMM=False)\n",
    "    sentence = sentence[:-1]\n",
    "    seq = [\"__SOS.Token__\"]\n",
    "    seq.extend(sentence)\n",
    "    seq.append(\"__EOS.Token__\")\n",
    "    over_max_length = 0\n",
    "    if len(seq) > max_seq_len:\n",
    "        print(\"Sentence is too long\")\n",
    "        over_max_length = 1\n",
    "    if over_max_length == 0:\n",
    "        input_tensor = strlist_to_vec(word_vectors,seq)\n",
    "        input_tensor = torch.tensor(input_tensor,dtype=dtype,device=device)\n",
    "        #禁止計算梯度\n",
    "        with torch.no_grad():\n",
    "            #記錄長度\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #初始化encoder的h0\n",
    "            encoder_hidden = initHidden(encoder.rnn_num_layers,encoder.hidden_size,device=device)\n",
    "            #儲存輸出的encoder\n",
    "            encoder_outputs = init_encoder_outputs(encoder.max_length, encoder.output_size, device=device)\n",
    "            #與train相同值行forward\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                         encoder_hidden)\n",
    "                encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "            decoder_input = input_tensor[0]\n",
    "            decoder_hidden = initHidden(encoder.rnn_num_layers,decoder.hidden_size, device=device)\n",
    "            #創建列表儲存預測的字\n",
    "            decoded_words = []\n",
    "            #decoder_attentions 學到的權重max_length的權重儲存，這個字學到的權重儲存\n",
    "            decoder_attentions = torch.zeros(max_length, max_length)\n",
    "            #不使用teacher_forcing\n",
    "            for di in range(max_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "#                 print(decoder_output.reshape(-1).cpu().numpy())\n",
    "                predict_word = wordvec2str(word_vectors,decoder_output.reshape(-1).cpu().numpy())\n",
    "                decoded_words.append(predict_word)\n",
    "                decoder_attentions[di] = decoder_attention.reshape(-1)\n",
    "                if predict_word == \"__EOS.Token__\":\n",
    "                    break\n",
    "                else:\n",
    "                    #將decoder_output作為下個序列的輸入\n",
    "                    decoder_input = decoder_output\n",
    "        return decoded_words, decoder_attentions,seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\"你好\",encoder1,attn_decoder1,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
